{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import causalimpact\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "from causalimpact import CausalImpact"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.random.seed(10)\n",
    "x = np.linspace(1, 200, 200)\n",
    "y = np.linspace(30, 100, 100)\n",
    "oney = np.ones(100) * 30\n",
    "yconc = np.concatenate([oney, y])\n",
    "ycontroll = np.ones(200) * 20\n",
    "noise = np.random.uniform(-5, 5, size=200)\n",
    "yfinal = np.add(yconc, noise)\n",
    "ycontrfin = np.add(ycontroll, noise)\n",
    "cm = 1 / 2.54\n",
    "fig3, ax3 = plt.subplots(figsize=(80 * cm, 40 * cm))\n",
    "ax3.plot(yfinal, linewidth=2.5, color='red', label='Treated group')\n",
    "ax3.plot(ycontrfin, linewidth=2.5, color='blue', label='Control group')\n",
    "plt.legend(fontsize=30, loc=\"best\")\n",
    "ax3.set_xlabel(\"200-period\", fontsize=17)\n",
    "ax3.set_ylabel(\"Value\", fontsize=17)\n",
    "ax3.grid()\n",
    "fig3.savefig('fig1.png')\n",
    "plt.show()"
   ],
   "id": "cfcb9255f2b4f944",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def IDID(df, t, c):\n",
    "    df1 = copy.deepcopy(df)\n",
    "    df1['time1'] = np.where(df1['time'] >= t, 1, 0)\n",
    "    df1['treated'] = np.where(df1['AB'] == c, 1, 0)\n",
    "    df1['did'] = df1['time1'] * df1['treated']\n",
    "    timed = df1['time1']\n",
    "    treatedd = df1['treated']\n",
    "    didd = df1['did']\n",
    "    y = df1['value']\n",
    "    res = smf.ols(formula='y ~ didd + timed + treatedd', data=df1).fit()\n",
    "    pv = res.pvalues[1]\n",
    "    cofidid = res.params.tolist()\n",
    "    return cofidid[1], pv"
   ],
   "id": "7c6930bab56636d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "listalldid = []\n",
    "listpv = []\n",
    "\n",
    "for i in x[1:]:\n",
    "    alldid = IDID(df, i, 'A')\n",
    "    listalldid.append(alldid[0])\n",
    "    listpv.append(alldid[1])"
   ],
   "id": "48853810278fab38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "listci = []\n",
    "for i in np.linspace(3, 196, 194):\n",
    "    print(i)\n",
    "    ci = CausalImpact(yfinal, [0, int(i)], [int(i) + 1, 199],\n",
    "    model_args={'fit_method': 'hmc'})\n",
    "    listci.append(ci)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "id": "fdf79cf7e15c6deb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "z = 0\n",
    "for ci in listci:\n",
    "    string = ci.summary()\n",
    "    print(string)\n",
    "    z = z + 1\n",
    "z = 0\n",
    "for ci in listci:\n",
    "    string = ci.summary(output='report')\n",
    "    print(string)\n",
    "    z = z + 1\n",
    "for ci in listci:\n",
    "    ci.plot()"
   ],
   "id": "935b71f8b6e15201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    max1 = tf.math.maximum(y_true, y_pred)\n",
    "    max2 = tf.reduce_sum(max1)\n",
    "    min1 = tf.math.minimum(y_true, y_pred)\n",
    "    min2 = tf.reduce_sum(min1)\n",
    "    jaccard = (1 - (min2 / max2)) * 100\n",
    "    return jaccard"
   ],
   "id": "4d826b1b689c9e17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        % find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        % check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "    % gather input and output parts of the pattern\n",
    "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ],
   "id": "a14f00b095fa2452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "listann = x[33:-15]\n",
    "result_final = []\n",
    "for j in listann:\n",
    "    range_seed = [123]\n",
    "    result_seed = []\n",
    "    for i in range_seed:\n",
    "        print(j, '---------------------------------------------------')\n",
    "        best_ep, best_cicle, val_mae_best, list_result_fin = bi_lstm_iteration(int(j), i, listadd)\n",
    "        print(list_result_fin)\n",
    "        parameter = list_result_fin.index(min(list_result_fin)\n",
    "        )\n",
    "        min_best_loss = best_ep[parameter]\n",
    "        mi_val_mae_best = val_mae_best[parameter]\n",
    "        best_cicle_select = best_cicle[parameter] + 1\n",
    "        list_cod_step = [8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "        best_step_select = list_cod_step[parameter]\n",
    "        print(min(list_result_fin), min_best_loss,\n",
    "            mi_val_mae_best, best_cicle_select,\n",
    "            best_step_select, i, j)\n",
    "        result_seed.append([min(list_result_fin),\n",
    "            min_best_loss, mi_val_mae_best, best_cicle_select,\n",
    "            best_step_select, i, j])\n",
    "    best_i = []\n",
    "    for i in result_seed:\n",
    "        best_i.append(i[0])\n",
    "    re = best_i.index(min(best_i))\n",
    "    result_final.append(result_seed[re])"
   ],
   "id": "45042deb1c9b6715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def bi_lstm_iteration(treatment_period, seed, data):\n",
    "    pre_period = [0, treatment_period]\n",
    "    post_period = [treatment_period + 1, 199]\n",
    "    list_steps = [8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "    best_epoch_value = []\n",
    "    best_epoch_cicle = []\n",
    "    list_val_mae = []\n",
    "    lista_result_fin = []\n",
    "    for step in list_steps:\n",
    "        seed_values = seed\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed_values)\n",
    "        random.seed(seed_values)\n",
    "        tf.random.set_seed(seed_values)\n",
    "        PaAn = pre_period[1]\n",
    "        parametro_inizio = pre_period[0]\n",
    "        raw_seq = data[0:treatment_period]\n",
    "        n_steps = step\n",
    "        X, y = split_sequence(raw_seq, n_steps)\n",
    "        n_features = 1\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=40)\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(50, activation='LeakyReLU'), input_shape=(n_steps, n_features)))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer='Adam', loss=custom_loss,\n",
    "        metrics='mae')\n",
    "        history = model.fit(X, y, epochs=100, validation_split\n",
    "        =0.33, callbacks=[callback], verbose=0)\n",
    "        list_val_loss = history.history['val_loss']\n",
    "        list_val_loss_mae = history.history['val_mae']\n",
    "        xmin = min(list_val_loss)\n",
    "        yindex = list_val_loss.index(xmin)\n",
    "        val_mae_val = list_val_loss_mae[yindex]\n",
    "        list_val_mae.append(val_mae_val)\n",
    "        best_epoch_cicle.append(yindex)\n",
    "        best_epoch_value.append(xmin)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed_values)\n",
    "        random.seed(seed_values)\n",
    "        tf.random.set_seed(seed_values)\n",
    "        model1 = Sequential()\n",
    "        model1.add(Bidirectional(LSTM(50, activation='LeakyReLU'), input_shape=(n_steps, n_features)))\n",
    "        model1.add(Dense(1))\n",
    "        model1.compile(optimizer='Adam', loss=custom_loss,\n",
    "        metrics='mae')\n",
    "        history1 = model1.fit(X, y, epochs=yindex+1,\n",
    "        validation_split=0.33, verbose=0)\n",
    "        yhat = model1.predict(X, verbose=1)\n",
    "        prediction = []\n",
    "        current_batch = np.array(yhat[:PaAn])[-n_steps:]\n",
    "        current_batch = current_batch.reshape(1, n_steps,\n",
    "        n_features)\n",
    "        for i in range(10):\n",
    "            current_pred = model1.predict(current_batch,\n",
    "            verbose=0)[0]\n",
    "            prediction.append(current_pred)\n",
    "            current_batch = np.append(current_batch[:, 1:, :],\n",
    "            [[current_pred]], axis=1)\n",
    "        observed = listadd[PaAn:PaAn+10]\n",
    "        resultfin = np.mean(np.array(observed) - np.array(\n",
    "        prediction))\n",
    "        listaresultfin.append(abs(resultfin))\n",
    "    return best_epoch_value, best_epoch_cicle, list_val_mae, listaresultfin\n"
   ],
   "id": "751bc62c0cb3463d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d4de6c5e4ed5807d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
