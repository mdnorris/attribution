{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 1: EDA Imports and Methods\n",
    "This EDA focused on time series and cross-sectional data. This EDA\n",
    "initially provides summary statistics, then does a test to see if there's a time series pattern.\n",
    "Then, if a dataset appears to have missing values, it imputes them. Regardless of whether or not\n",
    "the data is time series or not, it calculates feature importance. Finally, if it is a time series,\n",
    "it provides tests to determine the quality of the time series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:25:49.517340Z",
     "start_time": "2024-06-25T09:25:48.875286Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 128)\n",
    "pd.set_option('display.expand_frame_repr', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "# from fitter import Fitter, get_common_distributions, get_distributions\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pmdarima.arima import ADFTest\n",
    "from pmdarima.arima import auto_arima\n",
    "# from rfpimp import *\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from clusteval import clusteval\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import linear_model\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "from ydata_profiling import ProfileReport as ydata_prof\n",
    "from pandas_profiling import ProfileReport as pd_prof\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=ValueError)"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pmdarima'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 14\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# from fitter import Fitter, get_common_distributions, get_distributions\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplotting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autocorrelation_plot\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpmdarima\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marima\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ADFTest\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpmdarima\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marima\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m auto_arima\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# from rfpimp import *\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pmdarima'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "os.chdir('C:/Users/norri/Desktop/RW5/')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('C:/Users/norri/Desktop/RW5/ICRForm.csv')\n",
    "# df_date = pd.to_datetime(df['DATE'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following definitions are mostly used for descriptive statistics, but also provide\n",
    "feature importance metrics towards the end."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def missing_values(df):\n",
    "    \"\"\"\n",
    "\n",
    "    This function is used early on in the EDA to determine how manu\n",
    "    are missing.\n",
    "    \"\"\"\n",
    "    names = [var for var in df.columns]\n",
    "    missing_count = df[names].isnull().sum()\n",
    "    var_count = np.array(df[names].isnull().sum() * 100/ len(df)).round(2)\n",
    "    missing = pd.DataFrame(index=names)\n",
    "    missing[\"Count Missing\"] = missing_count\n",
    "    missing[\"Percent Missing\"] = var_count\n",
    "    print(missing)\n",
    "\n",
    "\n",
    "def unique(df):\n",
    "    \"\"\"\n",
    "\n",
    "    Like the above method, it calculates the number of unique entries.\n",
    "    \"\"\"\n",
    "    percent_unique = np.array(100 * df.nunique()/len(df.index)).round(2)\n",
    "    count_unique = df.nunique()\n",
    "    names = [var for var in df.columns]\n",
    "    unique_df = pd.DataFrame(index=names)\n",
    "    unique_df[\"Count Unique\"] = count_unique\n",
    "    unique_df[\"Percent Unique\"] = percent_unique\n",
    "    print(unique_df)\n",
    "\n",
    "\n",
    "def corr_plot(df):\n",
    "    \"\"\"\n",
    "\n",
    "    This provides a clean heatmap of correlations, though if too\n",
    "    many variables are in the dataset, it will b edifficult to read\n",
    "    \"\"\"\n",
    "    corr_temp = df.drop(['DATE'], axis=1)\n",
    "    corr_names = corr_temp.columns.tolist()\n",
    "    temp_df = df[corr_names]\n",
    "    corr = temp_df.corr(method=\"pearson\").round(2)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    f, ax = plt.subplots(figsize=(8, 8))\n",
    "    cmap = sns.diverging_palette(250, 1, as_cmap=True)\n",
    "    sns.heatmap(corr, annot=True, mask=mask, cmap=cmap,\n",
    "                vmax=1, vmin=-1, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "\n",
    "def distributions(df):\n",
    "    \"\"\"\n",
    "\n",
    "    This method tests the most common distributions and\n",
    "    keeps the two, as well as plotting the distribution\n",
    "    against a histogram of the data\n",
    "    \"\"\"\n",
    "    for var in temp_df:\n",
    "        dist_test = temp_df[var].dropna()\n",
    "        dist_test = dist_test.values\n",
    "        f = Fitter(dist_test, distributions='common', bins=100, timeout=30)\n",
    "        f.fit()\n",
    "        print(var)\n",
    "        print(f.summary(Nbest=2, clf=True, plot=True))\n",
    "        print(f.get_best(method='sumsquare_error'))\n",
    "\n",
    "\n",
    "def summary(df):\n",
    "    \"\"\"\n",
    "\n",
    "    This method simply pulls in three of the above methods\n",
    "    and reports them at once.\n",
    "    \"\"\"\n",
    "    print(missing_values(df))\n",
    "    print(unique(df))\n",
    "    corr_plot(df)\n",
    "\n",
    "\n",
    "def forecast_accuracy(forecast, Actuals):\n",
    "    \"\"\"\n",
    "\n",
    "    Calculates several accuracy metrics in the time series section\n",
    "    \"\"\"\n",
    "    mape = np.mean(np.abs(forecast - Actuals)/np.abs(Actuals))  # MAPE\n",
    "    mae = np.mean(np.abs(forecast - Actuals))    # MAE\n",
    "    mse = np.square(np.subtract(Actuals,forecast)).mean()\n",
    "    rmse = np.mean((forecast - Actuals)**2)**.5  # RMSE\n",
    "    smape = 1/len(Actuals) * np.sum(2 * np.abs(forecast-Actuals) / (np.abs(Actuals) + np.abs(forecast))*100)\n",
    "    return {'MAPE':mape, 'MSE':mse, 'MAE':mae, 'RMSE':rmse, 'SMAPE':smape}\n",
    "\n",
    "\n",
    "def plot_df(df, x, y, title=\"\", xlabel='DATE', ylabel='revenue', dpi=100):\n",
    "    \"\"\"\n",
    "\n",
    "    A plot that demonstrates a dataset may be a time series plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 4), dpi=dpi)\n",
    "    plt.plot(x, y, color='blue')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Section 2: Descriptive Statistics\n",
    "This section provides descriptive statistics on the original dataframe. Assuming\n",
    "some data is missing, not all the tests may work. Additionally, a basic time series\n",
    "plot gives insight into whether or not the data is time-based in nature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "summary(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This plot can give us a good initial ideal that there is a time series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plot_df(df, df['DATE'], df['revenue'], title='Sales Over Time')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 3: Prep for future analyses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = df[['DATE', 'revenue', 'display_S', 'b_branded_S', 'b_category_S',\n",
    "         'p_auto_S', 'p_brand_S', 'p_category_S', 'p_competitive_S']]\n",
    "temp_week = df['DATE']\n",
    "corr_temp = df.drop(['DATE'], axis=1)\n",
    "corr_names = corr_temp.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 4: Distribution Analysis and Descriptive Statistics\n",
    "To compare the original dataset and the imputations, each data set finds\n",
    "the top two distributions for every variable and its parameters. For imputations\n",
    "that are necessary for a large number of missing variables, checking this section\n",
    "and the next are crucial."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "temp_df = df.drop(['DATE'], axis=1)\n",
    "\n",
    "for var in temp_df:\n",
    "    dist_test = temp_df[var].dropna()\n",
    "    dist_test = dist_test.values\n",
    "    f = Fitter(dist_test, distributions='common', bins=100, timeout=30)\n",
    "    f.fit()\n",
    "    print(var)\n",
    "    print(f.summary(Nbest=2, clf=True, plot=True))\n",
    "    print(f.get_best(method='sumsquare_error'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 5: KNN and MICE Imputation\n",
    "This section uses the KNN and MICE methods of imputation. They are generally\n",
    "the most accurate of methods, though one or the other may be more accurate\n",
    "depending on the situation. It is important to note that if a data set with\n",
    "no missing values is run through the EDA, no differences will be noted in\n",
    "this section."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "knn_df_names = tuple(corr_names)\n",
    "knn_temp = df[corr_names]\n",
    "df_knn = knn_temp.filter(knn_df_names, axis=1).copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "knn_df_names = tuple(corr_names)\n",
    "knn_temp = df[corr_names]\n",
    "df_knn = knn_temp.filter(knn_df_names, axis=1).copy()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_knn = pd.DataFrame(scaler.fit_transform(df_knn), columns = df_knn.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5, weights='distance', metric='nan_euclidean')\n",
    "df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_knn), columns=df_knn.columns)\n",
    "df_knn_imputed = pd.DataFrame(scaler.inverse_transform(df_knn_imputed), columns=df_knn.columns)\n",
    "KNN_imputation = pd.concat([df_knn_imputed, temp_week], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mice_names = tuple(corr_names)\n",
    "mice_temp = df[corr_names]\n",
    "df_mice = mice_temp.filter(mice_names, axis=1).copy()\n",
    "mice_estimator = IterativeImputer(estimator=linear_model.BayesianRidge(), sample_posterior=True, max_iter=40,\n",
    "                                n_nearest_features=10, imputation_order='random')\n",
    "df_mice_imputed = pd.DataFrame(mice_estimator.fit_transform(df_mice), columns=df_mice.columns)\n",
    "df_mice_imputed = df_mice_imputed.apply(lambda x: x.abs(), axis=1)\n",
    "imputed_mice = pd.concat([df_mice_imputed, temp_week], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "imputed_mice.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "KNN_imputation.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 6: Distribution Analysis of Imputed Data\n",
    "This section is best used to compare if the top two distributions\n",
    "and their parameters differ from the others. It can suggest the\n",
    "imputation may be weak."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "temp_df = df.drop(['DATE'], axis=1)\n",
    "temp_mice = imputed_mice.drop(['DATE'], axis=1)\n",
    "temp_KNN = KNN_imputation.drop(['DATE'], axis=1)\n",
    "distributions(temp_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "distributions(temp_mice)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "distributions(temp_KNN)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 7: Imputation Distributions\n",
    "This section shows the distributions for all of the variables and\n",
    "can be used to determine how different they may be. The x-axis is\n",
    "in dollars, and the density is a way to represent the mass under\n",
    "the curve equally across variables with different properties."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cols = 3\n",
    "rows = 3\n",
    "num_cols = df.select_dtypes(exclude='object').columns\n",
    "fig = plt.figure(figsize=(cols * 3, rows * 3))\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    sns.kdeplot(data=imputed_mice[col])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "cols = 3\n",
    "rows = 3\n",
    "num_cols = df.select_dtypes(exclude='object').columns\n",
    "fig = plt.figure(figsize=(cols * 3, rows * 3))\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    sns.kdeplot(data=KNN_imputation[col])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 8: Original, KNN, and MICE Comparisons\n",
    "If the data has no missing values, the following plot will look unremarkable,\n",
    "but if data is imputed, three different curves will appear shifted, a useful\n",
    "method to determine how different the imputed data is. The last two summaries\n",
    "show the properties of the imputed data without the missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cols = 3\n",
    "rows = 3\n",
    "num_cols = df.select_dtypes(exclude='object').columns\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for i, col in enumerate(num_cols):\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    sns.kdeplot(data=imputed_mice[col], color='blue', legend=True)\n",
    "    sns.kdeplot(data=KNN_imputation[col], color='green', legend=True)\n",
    "    sns.kdeplot(data=df[col], color='red', legend=True)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "summary(imputed_mice)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "summary(KNN_imputation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 9: RFE Feature Importance\n",
    "This measure of feature importance is Recursive Feature Elimination. RFE uses an\n",
    "estimator, in this case RandomForestRegressor, to eliminate variables one by one\n",
    "until it meets a given threshold. This does not mean that the \"Selected False\"\n",
    "variables do not add to the model, but a good portion of the model's accuracy\n",
    "will remain even if they are dropped. It is possible to change the number of\n",
    "features selected to reduce or increse the features, if necessary."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = df.drop(['DATE', 'revenue'], axis=1)\n",
    "y = df['revenue']\n",
    "rfe = RFE(RandomForestRegressor(n_estimators=500, criterion='squared_error', bootstrap=False), importance_getter='auto')\n",
    "fit = rfe.fit(X, y)\n",
    "for i in range(X.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "print(X.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 10: Cluster Evaluation\n",
    "This method is another way to see the relationship between the dependent and independent\n",
    "variables. Clusters are evaluated by similarity and provided with a silhouette score between\n",
    "-1 and 1, with 1 meaning the clusters are very similar. The next two plots demonstrate\n",
    "the dissimilarity of the clusters, and the last plot a score between the chosen features\n",
    "and the dependent variable."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_no_date = df.drop('DATE', axis=1)\n",
    "\n",
    "ce = clusteval(cluster='agglomerative', evaluate='silhouette', metric='euclidean', linkage='complete', min_clust=5, verbose=None)\n",
    "results = ce.fit(df_no_date)\n",
    "ce.plot()\n",
    "ce.plot_silhouette(df_no_date)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "enrichment_results = ce.enrichment(df_no_date)\n",
    "ce.scatter(n_feat=2, figsize=(14,14))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 11: GridSearch\n",
    "A GridSearch can be used to iterate through many combinations of features\n",
    "to determine what the best combination is for the most accurate model. In this\n",
    "case, the initial GridSearch model is built, its best model used for prediction\n",
    "to determine a R-Squared score, then a feature importance rank is given. At this\n",
    "point, most of the previous models and the following feature importance methods\n",
    "should agree."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = df.drop(['DATE', 'revenue'], axis=1)\n",
    "y = df['revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.25)\n",
    "cv = KFold(n_splits=5)\n",
    "model = RandomForestRegressor()\n",
    "param_search = {'n_estimators': [10, 50, 100]}\n",
    "gs = GridSearchCV(estimator=model,\n",
    "                  refit=True,\n",
    "                  cv=cv,\n",
    "                  param_grid=param_search)\n",
    "gs.fit(X_train, y_train)\n",
    "best_model = RandomForestRegressor(**gs.best_params_)\n",
    "best_model.fit(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "performance = r2_score(y_test, preds)\n",
    "print(performance)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "final_model = RandomForestRegressor(**gs.best_params_)\n",
    "final_model.fit(X, y)\n",
    "final_model.feature_importances_"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(X.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 12: Feature Importance\n",
    "This sections uses a RandomForestClassifier and a permutation importance to rank the most important\n",
    "features. Ideally, this should match up with most or all of the previous feature assessments."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = df.drop(['DATE', 'revenue'], axis=1).astype(int)\n",
    "y = df['revenue'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1,\n",
    "                            max_features=1.0,\n",
    "                            min_samples_leaf=10, oob_score=True)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "I = pd.DataFrame()\n",
    "\n",
    "I['Feature'] = X_train.columns\n",
    "I['Importance'] = rf.feature_importances_\n",
    "I = I.sort_values('Importance', ascending=False)\n",
    "I = I.set_index('Feature')\n",
    "plot_importances(I, width=16, vscale=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)\n",
    "plt.plot(perm_imp_rfpimp)\n",
    "plot_importances(perm_imp_rfpimp, width=14, vscale=3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 13: Time Series Autocorrelation and Stationarity Tests\n",
    "The plot provides a simple visualization to determine if autocorrelation exists. If\n",
    "the line goes out of the bounds in the middle, autocorrelation exists. The second test,\n",
    "the Augmented Dickey-Fuller Test, tests for stationarity and if differencing is required.\n",
    "If the result is \"True\", it should require some degree of differencing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "plt.rcParams.update({'figure.figsize':(10,4), 'figure.dpi':120})\n",
    "autocorrelation_plot(imputed_mice['revenue'].tolist())"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.rcParams.update({'figure.figsize':(10,4), 'figure.dpi':120})\n",
    "autocorrelation_plot(KNN_imputation['revenue'].tolist())"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mice_no_date = imputed_mice[['revenue']]\n",
    "adf_test = ADFTest(alpha = .05)\n",
    "adf_test.should_diff(mice_no_date['revenue'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "knn_no_date = KNN_imputation[['revenue']]\n",
    "adf_test = ADFTest(alpha = .05)\n",
    "adf_test.should_diff(knn_no_date['revenue'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Section 14: Lag and Forecast Time Series Tests\n",
    "This last section first tests whether there is lag between one observation and\n",
    "the previous. Next, as an experiment, it performs an auto Arima and provides metrics\n",
    "and the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "ac1 = df['revenue'].autocorr(lag=1)\n",
    "print(\"One week Lag: \", ac1)\n",
    "ac2 = df['revenue'].autocorr(lag=2)\n",
    "print(\"Two week Lag: \", ac2)\n",
    "ac3 = df['revenue'].autocorr(lag=3)\n",
    "print(\"Three week Lag: \", ac3)\n",
    "ac4 = df['revenue'].autocorr(lag=4)\n",
    "print(\"Four Week Lag: \", ac4)\n",
    "ac5 = df['revenue'].autocorr(lag=5)\n",
    "print(\"Five Week Lag: \", ac5)\n",
    "ac6 = df['revenue'].autocorr(lag=6)\n",
    "print(\"Six Week Lag: \", ac6)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train = df['revenue'][:72]\n",
    "test = df['revenue'][100:]\n",
    "model = auto_arima(train, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "model.fit(train)\n",
    "forecast = model.predict(n_periods=len(test))\n",
    "forecast = pd.DataFrame(forecast,index = test.index,columns=['Prediction'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "forecast = forecast.squeeze()\n",
    "forecast_accuracy(forecast, test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# df_small = df[['DATE', 'revenue']]\n",
    "# result = adfuller(df_small.revenue.dropna())\n",
    "# print('ADF Statistic: %f' % result[0])\n",
    "# print('p-value: %f' % result[1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
